{"version":3,"sources":["../../src/parser/tokenizeFile.js"],"names":["tokenizeFile","context","filePath","Error","stream"],"mappings":";;;;;;;;;AAAA;;AAEA;;AAEA;;;;AAEA,MAAMA,YAAY,GAAG,OAAOC,OAAP,EAAgBC,QAAhB,KAA6B;AAChDA,EAAAA,QAAQ,GAAG,mBAAQA,QAAR,CAAX;;AACA,MAAI,EAAE,MAAM,yBAAWA,QAAX,CAAR,CAAJ,EAAmC;AACjC,UAAM,IAAIC,KAAJ,CAAW,eAAcD,QAAS,kBAAlC,CAAN;AACD;;AAED,QAAME,MAAM,GAAG,+BAAiBF,QAAjB,CAAf;AACA,SAAO,MAAM,6BAAeD,OAAf,EAAwB;AAAEG,IAAAA;AAAF,GAAxB,CAAb;AACD,CARD;;eAUeJ,Y","sourcesContent":["import { resolve } from 'path'\n\nimport { createReadStream, pathExists } from 'fs-extra'\n\nimport tokenizeStream from './tokenizeStream'\n\nconst tokenizeFile = async (context, filePath) => {\n  filePath = resolve(filePath)\n  if (!(await pathExists(filePath))) {\n    throw new Error(`rules file '${filePath}' does not exist`)\n  }\n\n  const stream = createReadStream(filePath)\n  return await tokenizeStream(context, { stream })\n}\n\nexport default tokenizeFile\n"],"file":"tokenizeFile.js"}